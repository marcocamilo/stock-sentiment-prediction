{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1489d3f2-28b1-4de6-bd1d-6f354a2ad87e",
   "metadata": {},
   "source": [
    "# GNU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a65034-e293-4488-b24a-b77567b10b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 14:59:40.342915: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "\n",
    "# Set default figure size\n",
    "figsize = (15,9)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Set default float size\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1499bc49-9425-49c6-923d-9c72c7e4eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/3-processed/stock-history-features.parquet\")\n",
    "df.insert(13, \"close\", df.pop(\"close\"))\n",
    "df.drop(\"date\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8af33a-bc32-434d-96b2-e59a8824ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockData:\n",
    "    def __init__(self, stock, data) -> None:\n",
    "        self.data = data.query(f\"stock == '{stock}'\").copy()\n",
    "        self.data.drop(\"stock\", axis=1, inplace=True)\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.data_scaled = self.scaler.fit_transform(self.data)\n",
    "\n",
    "    def create_sequences(self, data, look_back=30):\n",
    "        X, y = [], []\n",
    "\n",
    "        for i in range(len(data) - look_back):\n",
    "            X.append(data[i : i + look_back])\n",
    "            y.append(data[i + look_back])\n",
    "\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def split(self, train_factor=0.8):\n",
    "        split = int(len(self.data_scaled) * train_factor)\n",
    "        X_train, y_train = self.create_sequences(self.data_scaled[:split])\n",
    "        X_test, y_test = self.create_sequences(self.data_scaled[split:])\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad13652f-15aa-4205-91dc-c2642e17f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "TSLA = StockData(\"TSLA\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1913bdfe-5d14-4484-9009-18361c128329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_model:\n",
    "    def __init__(self, stock, units=64, dropout=0.2):\n",
    "        self.stock = stock\n",
    "        self.units = units\n",
    "        self.dropout = dropout\n",
    "        self.X_train, self.y_train, self.X_test, self.y_test = stock.split()\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self, input_shape, optimizer=\"rmsprop\", loss=\"mean_squared_error\"):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(GRU(self.units, return_sequences=True, input_shape=input_shape))\n",
    "        self.model.add(Dropout(self.dropout))\n",
    "        self.model.add(GRU(self.units, return_sequences=True))\n",
    "        self.model.add(Dropout(self.dropout))\n",
    "        self.model.add(GRU(self.units))\n",
    "        self.model.add(Dropout(self.dropout))\n",
    "        self.model.add(Dense(units=1))\n",
    "\n",
    "        self.model.compile(optimizer=optimizer, loss=loss)\n",
    "        print(self.model.summary())\n",
    "        \n",
    "    def print_summary(self):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model is not defined. Call build_model() first.\")\n",
    "        \n",
    "        print(self.model.summary())\n",
    "        \n",
    "    def train(self, epochs=30, batch_size=32, validation_split=0.2):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\n",
    "                \"Model is not defined. Call define_model() before training.\"\n",
    "            )\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor=\"val_loss\", patience=7, mode=\"min\")\n",
    "        history = self.model.fit(\n",
    "            self.X_train,\n",
    "            self.y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=validation_split,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        return history\n",
    "\n",
    "    def evaluate(self):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\n",
    "                \"Model is not defined. Call define_model() before training.\"\n",
    "            )\n",
    "\n",
    "        loss = self.model.evaluate(self.X_test, self.y_test)\n",
    "        print(f\"Test Loss: {loss}\")\n",
    "        return loss\n",
    "\n",
    "    def predict(self):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\n",
    "                \"Model is not defined. Call define_model() before training.\"\n",
    "            )\n",
    "\n",
    "        predictions = self.model.predict(self.X_test)\n",
    "        predictions = self.stock.scaler.inverse_transform(predictions)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def plot_history(self, history):\n",
    "        plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "        plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "        plt.title(f\"{self.stock} Model Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d8f01c-a2de-49a2-bfc0-0ffa01a3ca2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
